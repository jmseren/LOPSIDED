{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f056f2f3-b31f-4000-bfb7-ea016e9beb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c0e1fe-99c6-4f8f-a67b-58c75776cfd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key='sk-proj-xxxxxxxxxxxxxx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a82406-1759-48d8-8678-0ff317e507c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reply(api_response):\n",
    "    return json.loads(api_response['response']['body']['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791012c5-8b75-4ea1-817d-60f36033aef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_judge_score(answer):\n",
    "    return float(answer['total_rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a601e3ce-c079-4406-944b-adc77303a47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "JUDGE_PROMPT = \"\"\"\n",
    "You will be given a user_question and system_answer couple.\n",
    "Your task is to provide a 'total rating' scoring how well the system_answer answers the user concerns expressed in the user_question.\n",
    "Give your answer on a scale of 1 to 4, where 1 means that the system_answer is not helpful at all, and 4 means that the system_answer completely and helpfully addresses the user_question.\n",
    "\n",
    "Here is the scale you should use to build your answer:\n",
    "1: The system_answer is terrible: completely irrelevant to the question asked, or very partial\n",
    "2: The system_answer is mostly not helpful: misses some key aspects of the question\n",
    "3: The system_answer is mostly helpful: provides support, but still could be improved\n",
    "4: The system_answer is excellent: relevant, direct, detailed, and addresses all the concerns raised in the question\n",
    "\n",
    "Provide your feedback as follows:\n",
    "\n",
    "Evaluation: your rationale for the rating, as a text\n",
    "Total rating: your rating, as a number between 1 and 4\n",
    "\n",
    "You MUST provide values for 'Evaluation' and 'Total rating' in your answer.\n",
    "\n",
    "Now here are the question and answer.\n",
    "\n",
    "Question: {question}\n",
    "Answer: {answer}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097894ee-a3ce-44e7-8f28-f22f31cdc559",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('prompts.json') as f:\n",
    "    prompts = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509ab661-80f0-4074-8ccc-e4811ee797d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch(lst, size=16):\n",
    "    batches = []\n",
    "    import math\n",
    "    for i in range(math.ceil(len(lst) / float(size))):\n",
    "        batches.append(lst[i*size:(i*size)+size])\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9524383b-10d5-4b89-8316-5df76c451edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i, b in enumerate(batch(prompts[:1000])):\n",
    "    if i == 15 or i == 62:\n",
    "        print(i)\n",
    "        continue\n",
    "    temp += b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47c9ee0-6a5d-465f-bc9a-1e0d9372f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d0f11a-759b-4a74-a105-5005c849a249",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_to_eval_responses.json') as f:\n",
    "    answers = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e08ff-cc6f-4889-855b-a780437df56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = [a[0]['generated_text'][-1] for a in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b6c835-f377-47a2-b3dc-161286420949",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = [a['content'] for a in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466b1f09-8d11-4f66-b573-6b5faaed0a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "            \"type\": \"json_schema\",\n",
    "            \"json_schema\": {\n",
    "                \"name\": \"llm_judge\",\n",
    "                \"schema\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"evaluation\": {\"type\": \"string\"},\n",
    "                        \"total_rating\": {\"type\": \"number\"}\n",
    "                    },\n",
    "                    \"required\": [\"evaluation\", \"total_rating\"],\n",
    "                    \"additionalProperties\": False\n",
    "                },\n",
    "                \"strict\": True\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c11e4e-24ed-4861-ad42-78e5b4020c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(question, answer):\n",
    "    if not type(question) == list:\n",
    "        question = [question]\n",
    "        answer = [answer]\n",
    "    return [\n",
    "        JUDGE_PROMPT.format(\n",
    "            question=q.replace('\\n', ''),\n",
    "            answer=a.replace('\\n', '')\n",
    "        )\n",
    "        for q, a in zip (question, answer)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1cefca-bb6b-4886-89c1-1119db9817b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = []\n",
    "\n",
    "lopsided_formatted = process(prompts, answers)\n",
    "\n",
    "\n",
    "for i, prompt in enumerate(lopsided_formatted):\n",
    "    processed.append({\n",
    "        \"custom_id\": \"prompt\" + str(i),\n",
    "        \"method\": \"POST\",\n",
    "        \"url\": \"/v1/chat/completions\",\n",
    "        \"body\": {\n",
    "            \"model\": \"gpt-4o-mini\", \n",
    "            \"messages\": [{'role': 'user', 'content': prompt}], \n",
    "            \"temperature\": 0.0,\n",
    "            \"response_format\": schema\n",
    "            \n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaa867d-3612-40b1-94c4-af7e185dbf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsonl = '\\n'.join([json.dumps(line) for line in processed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efce7a3f-01e6-49d5-857f-ec55a85c2f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('readybatch.jsonl', 'w') as f:\n",
    "    f.write(jsonl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96197fc-088d-4d52-bdb7-ae6d4159ddfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_input_file = client.files.create(\n",
    "  file=open(\"readybatch.jsonl\", \"rb\"),\n",
    "  purpose=\"batch\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c91fa9-e225-458d-a739-abe9c5ece59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input_file_id = batch_input_file.id\n",
    "\n",
    "client.batches.create(\n",
    "    input_file_id=batch_input_file_id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\",\n",
    "    metadata={\n",
    "      \"description\": \"LOPSIDED: LM As A Judge.\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ccecc2-2cf6-49b4-8507-7567be31c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('judge_responses.jsonl')as f:\n",
    "    judge = [json.loads(l) for l in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9d7b8-c0a8-4d87-8c6a-aff13f57c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_txt = [extract_judge_score(extract_reply(s)) for s in judge]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f30fc01b-b1da-4168-84fe-6904d5accd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57a0478-d528-4c08-8d04-15409a931107",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(judge_txt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
